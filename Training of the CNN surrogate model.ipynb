{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20122,"status":"ok","timestamp":1718609878796,"user":{"displayName":"Thijs Modderman","userId":"11652395558976171545"},"user_tz":-120},"id":"YGZt9XcBusuK","outputId":"4f897dde-7b0f-4951-d4bd-ae192d6b5148"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# Connect to the drive\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":55260,"status":"ok","timestamp":1718609934049,"user":{"displayName":"Thijs Modderman","userId":"11652395558976171545"},"user_tz":-120},"id":"A9kcW_geV7iX","outputId":"aafd4ae9-de13-4b28-985d-1e1352ad273a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting segmentation_models\n","  Downloading segmentation_models-1.0.1-py3-none-any.whl (33 kB)\n","Collecting keras-applications<=1.0.8,>=1.0.7 (from segmentation_models)\n","  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting image-classifiers==1.0.0 (from segmentation_models)\n","  Downloading image_classifiers-1.0.0-py3-none-any.whl (19 kB)\n","Collecting efficientnet==1.0.0 (from segmentation_models)\n","  Downloading efficientnet-1.0.0-py3-none-any.whl (17 kB)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from efficientnet==1.0.0->segmentation_models) (0.19.3)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation_models) (1.25.2)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation_models) (3.9.0)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (1.11.4)\n","Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (3.3)\n","Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (9.4.0)\n","Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2.31.6)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2024.5.22)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (1.6.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (24.1)\n","Installing collected packages: keras-applications, image-classifiers, efficientnet, segmentation_models\n","Successfully installed efficientnet-1.0.0 image-classifiers-1.0.0 keras-applications-1.0.8 segmentation_models-1.0.1\n","Collecting keras_applications==1.0.7\n","  Downloading Keras_Applications-1.0.7-py2.py3-none-any.whl (51 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from keras_applications==1.0.7) (1.25.2)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras_applications==1.0.7) (3.9.0)\n","Installing collected packages: keras_applications\n","  Attempting uninstall: keras_applications\n","    Found existing installation: Keras-Applications 1.0.8\n","    Uninstalling Keras-Applications-1.0.8:\n","      Successfully uninstalled Keras-Applications-1.0.8\n","Successfully installed keras_applications-1.0.7\n","Requirement already satisfied: efficientnet==1.0.0 in /usr/local/lib/python3.10/dist-packages (1.0.0)\n","Requirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in /usr/local/lib/python3.10/dist-packages (from efficientnet==1.0.0) (1.0.7)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from efficientnet==1.0.0) (0.19.3)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet==1.0.0) (1.25.2)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet==1.0.0) (3.9.0)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0) (1.11.4)\n","Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0) (3.3)\n","Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0) (9.4.0)\n","Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0) (2.31.6)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0) (2024.5.22)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0) (1.6.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0) (24.1)\n"]}],"source":["# Install the necessary packages\n","!pip install segmentation_models\n","!pip install keras_applications==1.0.7\n","!pip install efficientnet==1.0.0"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6899,"status":"ok","timestamp":1718609940944,"user":{"displayName":"Thijs Modderman","userId":"11652395558976171545"},"user_tz":-120},"id":"rFRervTrWE44","outputId":"d4294a62-d824-4528-dcbf-971985d59fb9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Segmentation Models: using `tf.keras` framework.\n"]}],"source":["# change SM framework to tensorflow keras\n","import os\n","os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n","\n","from tensorflow import keras\n","import segmentation_models as sm\n","\n","# Set channels first, since the channels are the first dimension ( (2, 416, 704) for input, and (3, 416, 704) for output)\n","keras.backend.set_image_data_format('channels_first')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KYnrwgfTWJl0"},"outputs":[],"source":["# Import libraries\n","from segmentation_models import Linknet, Unet, FPN\n","from segmentation_models import get_preprocessing\n","from segmentation_models.losses import bce_jaccard_loss\n","from segmentation_models.metrics import iou_score\n","import keras\n","import os\n","import pandas as pd\n","import numpy as np"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9g4q0N3dr0HX"},"outputs":[],"source":["img_dir = '' # Give location of all the input data\n","files = os.listdir(img_dir)\n","\n","data = pd.read_csv(img_dir + \"/\" + files[0])\n","input_data = data.Y\n","\n","mean_y = np.mean(input_data)\n","std_y  = np.std(input_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yruy_Foyeb3x"},"outputs":[],"source":["# define custom dataset class\n","# For data loading during model train and testing\n","import torch\n","from torch.utils.data import Dataset\n","from torchvision import datasets\n","from torchvision.transforms import ToTensor\n","import matplotlib.pyplot as plt\n","\n","import numpy as np\n","import os\n","import pandas as pd\n","from torchvision.io import read_image\n","\n","from sklearn.preprocessing import MinMaxScaler\n","\n","\n","class CustomImageDataset(Dataset):\n","    def __init__(self, label_dir, img_dir, annotation_dir, transform=None, target_transform=None):\n","        self.label_dir = label_dir\n","        self.annotations = pd.read_csv(annotation_dir, delimiter = ';') # to dir\n","        self.img_dir = img_dir\n","        self.transform = transform\n","        self.target_transform = target_transform\n","        self.target_shape = (416, 704)\n","    def __len__(self):\n","        return len(os.listdir(self.label_dir))-2\n","        #return len(self.img_labels)\n","\n","    def __getitem__(self, idx):\n","        # input data\n","        input_path = os.path.join(self.img_dir, self.annotations.iloc[idx, 0])\n","        input = pd.read_csv(input_path)\n","        image = (input.Y-mean_y)/std_y\n","        image = pd.DataFrame(image.values.reshape(401, 701))\n","        image = np.pad(image, ((0, 15), (0, 3)), mode='constant')\n","        wind_inlet = input.inlet_wind_normal_surf_diff\n","        wind_inlet = pd.DataFrame(wind_inlet.values.reshape(401, 701))\n","        wind_inlet = np.pad(wind_inlet, ((0, 15), (0, 3)), mode='constant')\n","        input_data = np.stack((image, wind_inlet))\n","\n","        # output data\n","        label_path = os.path.join(self.label_dir, self.annotations.iloc[idx, 1])\n","        label = pd.read_csv(label_path)\n","\n","        U_0 = label.loc[:, \"U_0\"]\n","        U_0 = (U_0-np.mean(U_0))/np.std(U_0)\n","\n","        U_1 = label.loc[:, \"U_1\"]\n","        U_1 = (U_1-np.mean(U_1))/np.std(U_1)\n","\n","        U_2 = label.loc[:, \"U_2\"]\n","        U_2 = (U_2-np.mean(U_2))/np.std(U_2)\n","\n","        U_0 = pd.DataFrame(U_0.values.reshape(401, 701))\n","        U_1 = pd.DataFrame(U_1.values.reshape(401, 701))\n","        U_2 = pd.DataFrame(U_2.values.reshape(401, 701))\n","\n","        U_0 = np.pad(U_0, ((0, 15), (0, 3)), mode='constant')\n","        U_1 = np.pad(U_1, ((0, 15), (0, 3)), mode='constant')\n","        U_2 = np.pad(U_2, ((0, 15), (0, 3)), mode='constant')\n","\n","        output_data = np.stack((U_0, U_1, U_2))\n","\n","        return input_data, output_data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y9tF4jnoeW-x"},"outputs":[],"source":["# Define custom dataloader class\n","# for our specific data\n","from torch.utils.data import DataLoader\n","class Dataloder(keras.utils.Sequence):\n","    \"\"\"Load data from dataset and form batches\n","\n","    Args:\n","        dataset: instance of Dataset class for image loading and preprocessing.\n","        batch_size: Integet number of images in batch.\n","        shuffle: Boolean, if `True` shuffle image indexes each epoch.\n","    \"\"\"\n","\n","    def __init__(self, dataset, batch_size=1, shuffle=False):\n","        self.dataset = dataset\n","        self.batch_size = batch_size\n","        self.shuffle = shuffle\n","        self.indexes = np.arange(len(dataset))\n","\n","        self.on_epoch_end()\n","\n","    def __getitem__(self, i):\n","\n","        # collect batch data\n","        start = i * self.batch_size\n","        stop = (i + 1) * self.batch_size\n","        data = []\n","        for j in range(start, stop):\n","            data.append(self.dataset[j])\n","\n","        # transpose list of lists\n","        batch = [np.stack(samples, axis=0) for samples in zip(*data)]\n","\n","        return batch\n","\n","    def __len__(self):\n","        \"\"\"Denotes the number of batches per epoch\"\"\"\n","        return len(self.indexes) // self.batch_size\n","\n","    def on_epoch_end(self):\n","        \"\"\"Callback function to shuffle indexes each epoch\"\"\"\n","        if self.shuffle:\n","            self.indexes = np.random.permutation(self.indexes)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dJag8mmpGWP-"},"outputs":[],"source":["# define cumtom dataset for the test set\n","class CustomImageDataset_test(Dataset):\n","    def __init__(self, label_dir, img_dir, transform=None, target_transform=None):\n","        self.label_dir = label_dir\n","        self.img_dir = img_dir\n","        self.transform = transform\n","        self.target_transform = target_transform\n","        self.target_shape = (416, 704)\n","    def __len__(self):\n","        return 1\n","        #return len(self.img_labels)\n","\n","    def __getitem__(self, idx):\n","        # input data\n","        input = pd.read_csv(self.img_dir)\n","        image = (input.Y-mean_y)/std_y\n","        image = pd.DataFrame(image.values.reshape(401, 701))\n","        image = np.pad(image, ((0, 15), (0, 3)), mode='constant')\n","        wind_inlet = input.inlet_wind_normal_surf_diff\n","        wind_inlet = pd.DataFrame(wind_inlet.values.reshape(401, 701))\n","        wind_inlet = np.pad(wind_inlet, ((0, 15), (0, 3)), mode='constant')\n","        input_data = np.stack((image, wind_inlet))\n","\n","        label = pd.read_csv(self.label_dir)\n","\n","        # output data\n","        U_0 = label.loc[:, \"U_0\"]\n","        U_0 = (U_0-np.mean(U_0))/np.std(U_0)\n","\n","        U_1 = label.loc[:, \"U_1\"]\n","        U_1 = (U_1-np.mean(U_1))/np.std(U_1)\n","\n","        U_2 = label.loc[:, \"U_2\"]\n","        U_2 = (U_2-np.mean(U_2))/np.std(U_2)\n","\n","        U_0 = pd.DataFrame(U_0.values.reshape(401, 701))\n","        U_1 = pd.DataFrame(U_1.values.reshape(401, 701))\n","        U_2 = pd.DataFrame(U_2.values.reshape(401, 701))\n","\n","        U_0 = np.pad(U_0, ((0, 15), (0, 3)), mode='constant')\n","        U_1 = np.pad(U_1, ((0, 15), (0, 3)), mode='constant')\n","        U_2 = np.pad(U_2, ((0, 15), (0, 3)), mode='constant')\n","\n","        output_data = np.stack((U_0, U_1, U_2))\n","\n","        return input_data, output_data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yP0xTO6yWZyY"},"outputs":[],"source":["# make the custom dataset\n","label_dir = '' # Give location of the output (target) data\n","img_dir = '' # Give location of the input data\n","\n","annotation_dir = '' # Give the location of the annotation file\n","\n","# define the dataset\n","dataset = CustomImageDataset(label_dir, img_dir, annotation_dir)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":414,"status":"ok","timestamp":1718609955293,"user":{"displayName":"Thijs Modderman","userId":"11652395558976171545"},"user_tz":-120},"id":"NaJ8goVHk1UH","outputId":"49617d71-ae86-42f9-e4d7-9390b913613d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                          input_file  \\\n","0  Copy of angle_-10_inlet_wind_normal_surf_diff.csv   \n","1  Copy of angle_-40_inlet_wind_normal_surf_diff.csv   \n","2  Copy of angle_-60_inlet_wind_normal_surf_diff.csv   \n","3  Copy of angle_-70_inlet_wind_normal_surf_diff.csv   \n","4    Copy of angle_0_inlet_wind_normal_surf_diff.csv   \n","\n","                                         output_file  \n","0  Copy of angle_-10_export_postprocessing_U_DEM_...  \n","1  Copy of angle_-40_export_postprocessing_U_DEM_...  \n","2  Copy of angle_-60_export_postprocessing_U_DEM_...  \n","3  Copy of angle_-70_export_postprocessing_U_DEM_...  \n","4  Copy of angle_0_export_postprocessing_U_DEM_be...  "],"text/html":["\n","  <div id=\"df-4a290f0e-480b-43bb-a3a5-3a14ad4a6461\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>input_file</th>\n","      <th>output_file</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Copy of angle_-10_inlet_wind_normal_surf_diff.csv</td>\n","      <td>Copy of angle_-10_export_postprocessing_U_DEM_...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Copy of angle_-40_inlet_wind_normal_surf_diff.csv</td>\n","      <td>Copy of angle_-40_export_postprocessing_U_DEM_...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Copy of angle_-60_inlet_wind_normal_surf_diff.csv</td>\n","      <td>Copy of angle_-60_export_postprocessing_U_DEM_...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Copy of angle_-70_inlet_wind_normal_surf_diff.csv</td>\n","      <td>Copy of angle_-70_export_postprocessing_U_DEM_...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Copy of angle_0_inlet_wind_normal_surf_diff.csv</td>\n","      <td>Copy of angle_0_export_postprocessing_U_DEM_be...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4a290f0e-480b-43bb-a3a5-3a14ad4a6461')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-4a290f0e-480b-43bb-a3a5-3a14ad4a6461 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-4a290f0e-480b-43bb-a3a5-3a14ad4a6461');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-4dcf4489-6bae-48c8-8d8c-96e48bdb80cc\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4dcf4489-6bae-48c8-8d8c-96e48bdb80cc')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-4dcf4489-6bae-48c8-8d8c-96e48bdb80cc button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"annotations","summary":"{\n  \"name\": \"annotations\",\n  \"rows\": 13,\n  \"fields\": [\n    {\n      \"column\": \"input_file\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 13,\n        \"samples\": [\n          \"Copy of angle_-50_inlet_wind_normal_surf_diff.csv\",\n          \"Copy of angle_20_inlet_wind_normal_surf_diff.csv\",\n          \"Copy of angle_-10_inlet_wind_normal_surf_diff.csv\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"output_file\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 13,\n        \"samples\": [\n          \"Copy of angle_-50_export_postprocessing_U_DEM_bed_distance_1.0.csv\",\n          \"Copy of angle_20_export_postprocessing_U_DEM_bed_distance_1.0.csv\",\n          \"Copy of angle_-10_export_postprocessing_U_DEM_bed_distance_1.0.csv\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":11}],"source":["annotations = pd.read_csv(annotation_dir, delimiter = ';')\n","annotations.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9LX1NFMhYUB0"},"outputs":[],"source":["# Extract the angle of the test fold\n","# For generic running of the code\n","import re\n","def extract_angle(s):\n","    # Define the regular expression pattern to match the angle degrees\n","    pattern = r'angle_(-?\\d+)_'\n","\n","    # Search for the pattern in the string\n","    match = re.search(pattern, s)\n","\n","    if match:\n","        # Extract the angle value and convert it to an integer\n","        angle = int(match.group(1))\n","        return angle\n","    else:\n","        raise ValueError(\"No valid angle found in the string\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cIyy1hcImZvG"},"outputs":[],"source":["# define test and validation inlet angles (indexes of the annotation file)\n","test_indices = [[0, 3], [2, 5], [9, 11], [1, 7], [8, 10]]\n","val_indices = [4, 6, 12]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NO7sWdVEqVa8"},"outputs":[],"source":["# Create new directory to store all the results and the best model\n","directory = ''\n","\n","# Define the names of the folders for each fold that will be created\n","angle_dirs = ['Fold 1', 'Fold 2', 'Fold 3', 'Fold 4', 'Fold 5']"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1w94bXorpnGGBFca4gF0EZk4DKfmvzYEe"},"id":"AM7dQr9vnX8M","outputId":"fc310c1b-4fa0-40aa-f448-9ff8c86dc40e","executionInfo":{"status":"ok","timestamp":1718613198935,"user_tz":-120,"elapsed":3232507,"user":{"displayName":"Thijs Modderman","userId":"11652395558976171545"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["# Train and test the CNN model\n","\n","from torch.utils.data import Subset\n","from sklearn.metrics import mean_squared_error\n","import matplotlib.pyplot as plt\n","import time\n","\n","# Define metric and loss function\n","metric = keras.metrics.RootMeanSquaredError()\n","loss = keras.losses.MeanSquaredError()\n","\n","# Define backbone\n","backbone = 'efficientnetb7' #'resnet152' #'densenet121'\n","\n","for count, test_pair in enumerate(test_indices[3:]):\n","\n","  model_dir = directory + angle_dirs[count+3]\n","\n","  callbacks = [\n","    keras.callbacks.ModelCheckpoint(model_dir + '/best_model.h5', save_weights_only=True, save_best_only=True, mode='min'),\n","    keras.callbacks.ReduceLROnPlateau(),\n","  ]\n","\n","  # Get the 2 test angles\n","  output_dir = annotations.output_file[test_pair[0]]\n","  input_dir = annotations.input_file[test_pair[0]]\n","  test_label = label_dir + \"/\" + output_dir\n","  angle1 = extract_angle(test_label)\n","\n","  output_dir = annotations.output_file[test_pair[1]]\n","  input_dir = annotations.input_file[test_pair[1]]\n","  test_label = label_dir + \"/\" + output_dir\n","  angle2 = extract_angle(test_label)\n","  angles = [angle1, angle2]\n","\n","\n","\n","  # Define test set\n","  test_set = Subset(dataset, test_pair)\n","\n","  # Define validation set\n","  validation_set = Subset(dataset, val_indices)\n","\n","  # Define train set\n","  exclude = test_pair + val_indices\n","  train_indices = np.arange(0, 13)            # Total of 13 datapoints\n","  train_indices = np.delete(train_indices, exclude) # Exclude the test and validation datapoints from training\n","  train_set = Subset(dataset, train_indices)\n","\n","  # Define loaders\n","  train_loader = Dataloder(dataset = train_set, batch_size = 2, shuffle=True)\n","  validation_loader = Dataloder(dataset = validation_set)\n","  test_loader = Dataloder(dataset = test_set)\n","\n","  # Define & compile the model\n","  model = Linknet(backbone_name=backbone, encoder_weights=None, input_shape=(2, None, None), classes = 3, activation = 'linear') # Here you can adjust the type of CNN architecture\n","  model.compile('Adam', loss=loss, metrics=[metric])\n","\n","  start_time = time.time()\n","  # Train the model with datapoint i left out\n","  history = model.fit_generator(\n","    train_loader,\n","    steps_per_epoch=len(train_loader),\n","    epochs=75,\n","    callbacks=callbacks,\n","    validation_data=validation_loader,\n","    validation_steps=len(validation_loader)\n","  )\n","  end_time = time.time()\n","  train_time = end_time - start_time\n","\n","  # save train time\n","  with open(model_dir + f'/train_time_test_angles_{angle1}_{angle2}.txt', 'w') as f:\n","      f.write(str(train_time))\n","\n","  ## plot training graph\n","  import matplotlib.pyplot as plt\n","\n","  # Plot both root_mean_squared_error and loss in the same figure\n","  plt.figure(figsize=(16, 8))\n","\n","  # Plot root_mean_squared_error\n","  plt.subplot(121)\n","  plt.plot(history.history['root_mean_squared_error'])\n","  plt.plot(history.history['val_root_mean_squared_error'])  # Add validation RMSE\n","  plt.title('Model RMSE score')\n","  plt.ylabel('RMSE')\n","  plt.xlabel('Epoch')\n","  plt.legend(['Train', 'Validation'], loc='upper left')\n","  #plt.ylim(0, 10)  # Set y-axis limit to 70\n","\n","  # Plot loss (MSE)\n","  plt.subplot(122)\n","  plt.plot(history.history['loss'])\n","  plt.plot(history.history['val_loss'])  # Add validation loss\n","  plt.title('Model loss')\n","  plt.ylabel('Loss (MSE)')\n","  plt.xlabel('Epoch')\n","  plt.legend(['Train', 'Validation'], loc='upper right')\n","  #plt.ylim(0, 90)  # Set y-axis limit to 70\n","  plt.savefig(model_dir + f'/Training_graph_test_angles_{angle1}_{angle2}.png') #{angle1} & {angle2}.png')\n","  plt.show()\n","\n","  # save raw data of the training graph\n","  training_data = {\n","      'rmse': history.history['root_mean_squared_error'],\n","      'val_rmse': history.history['val_root_mean_squared_error'],\n","      'loss': history.history['loss'],\n","      'val_loss': history.history['val_loss']\n","  }\n","\n","  training_graph_data = pd.DataFrame(training_data)\n","  training_graph_data.to_csv(model_dir + f'/Training_graph_data_test_angles_{angle1}_{angle2}.csv')\n","\n","  # Load the best model\n","  model.load_weights(model_dir + '/best_model.h5')\n","\n","  # predict, evaluate and plot the testset\n","  for i in range(len(test_pair)):\n","    # Extract the angle of the fold\n","    angle = angles[i]\n","\n","    # Compute the std and mean of the U_i to get the orgininal values\n","    label_path = os.path.join(label_dir, annotations.iloc[test_pair[i], 1])\n","    label = pd.read_csv(label_path)\n","    U_0 = label.loc[:, \"U_0\"]\n","    mean_0 = np.mean(U_0)\n","    std_0  = np.std(U_0)\n","\n","    U_1 = label.loc[:, \"U_1\"]\n","    mean_1 = np.mean(U_1)\n","    std_1  = np.std(U_1)\n","\n","    U_2 = label.loc[:, \"U_2\"]\n","    mean_2 = np.mean(U_2)\n","    std_2  = np.std(U_2)\n","\n","    # Predict on the correct testset\n","    prediction = model.predict(test_loader[i][0])\n","\n","    # Rescale the predictions and ground truth data\n","    ground_truth_0 = test_loader[i][1][0][0][:-15, :-3]*std_0 + mean_0\n","    ground_truth_1 = test_loader[i][1][0][1][:-15, :-3]*std_1 + mean_1\n","    ground_truth_2 = test_loader[i][1][0][2][:-15, :-3]*std_2 + mean_2 # probably needs and extra [0] between [1] and [2]\n","    ground_truths = [ground_truth_0, ground_truth_1, ground_truth_2]\n","\n","    prediction_0 = prediction[0][0][:-15, :-3]*std_0 + mean_0\n","    prediction_1 = prediction[0][1][:-15, :-3]*std_1 + mean_1\n","    prediction_2 = prediction[0][2][:-15, :-3]*std_2 + mean_2\n","    predictions = [prediction_0, prediction_1, prediction_2]\n","\n","    # Compute model performance with fold i\n","    actual_rmse_value_0 = np.sqrt(mean_squared_error(ground_truth_0, prediction_0))\n","    actual_rmse_value_1 = np.sqrt(mean_squared_error(ground_truth_1, prediction_1))\n","    actual_rmse_value_2 = np.sqrt(mean_squared_error(ground_truth_2, prediction_2))\n","    actual_rmse = [actual_rmse_value_0, actual_rmse_value_1, actual_rmse_value_2]\n","\n","    # Compute model performance with fold i\n","    standardized_rmse_value_0 = np.sqrt(mean_squared_error(test_loader[i][1][0][0][:-15, :-3], prediction[0][0][:-15, :-3]))\n","    standardized_rmse_value_1 = np.sqrt(mean_squared_error(test_loader[i][1][0][1][:-15, :-3], prediction[0][1][:-15, :-3]))\n","    standardized_rmse_value_2 = np.sqrt(mean_squared_error(test_loader[i][1][0][2][:-15, :-3], prediction[0][2][:-15, :-3]))\n","    standardized_rmse = [standardized_rmse_value_0, standardized_rmse_value_1, standardized_rmse_value_2]\n","\n","    ## Save the different RMSE values in a txt file\n","    with open(model_dir + f'/actual_rmse_test_angle_{angle}.txt', 'w') as f:\n","        f.write(f\"RMSE_0: {actual_rmse_value_0:.4f}\\n\")\n","        f.write(f\"RMSE_1: {actual_rmse_value_1:.4f}\\n\")\n","        f.write(f\"RMSE_2: {actual_rmse_value_2:.4f}\\n\")\n","\n","    ## Save the different RMSE values in a txt file\n","    with open(model_dir + f'/standardized_rmse_test_angle_{angle}.txt', 'w') as f:\n","        f.write(f\"RMSE_0: {standardized_rmse_value_0:.4f}\\n\")\n","        f.write(f\"RMSE_1: {standardized_rmse_value_1:.4f}\\n\")\n","        f.write(f\"RMSE_2: {standardized_rmse_value_2:.4f}\\n\")\n","\n","    # Used to keep prediction and True velocity values on the same axis\n","    levels_U_0 = np.linspace(min(ground_truth_0.min(), prediction_0.min()), max(ground_truth_0.max(), prediction_0.max()), 100)\n","    levels_U_1 = np.linspace(min(ground_truth_1.min(), prediction_1.min()), max(ground_truth_1.max(), prediction_1.max()), 100)\n","    levels_U_2 = np.linspace(min(ground_truth_2.min(), prediction_2.min()), max(ground_truth_2.max(), prediction_2.max()), 100)\n","    levels = [levels_U_0, levels_U_1, levels_U_2]\n","\n","    ## Plot and save the different graphs\n","    fig, axes = plt.subplots(3, 3, figsize=(18, 8), sharex=True, sharey=True)  # Create a figure with 3 subplots\n","    for j in range(3):\n","        # plot ground truths\n","        plot_values = ground_truths[j]\n","        ax = axes[0, j]\n","        p1 = ax.contourf(plot_values, levels=levels[j], cmap='jet')\n","        fig.colorbar(p1, ax=ax)\n","        ax.title.set_text(f'Ground truth U_{j} of angle {angle}')\n","        ax.set_xlabel('X-axis')\n","        ax.set_ylabel('Z-axis')\n","\n","        # plot predictions\n","        plot_values = predictions[j]\n","        ax = axes[1, j]\n","        p2 = ax.contourf(plot_values, levels=levels[j], cmap='jet')\n","        fig.colorbar(p2, ax=ax)\n","        ax.set_title(f'Prediction U_{j-3} of angle {angle}')\n","        ax.set_xlabel('X-axis')\n","        ax.set_ylabel('Z-axis')\n","\n","        # plot errors\n","        plot_values = predictions[j] - ground_truths[j]\n","        ax = axes[2, j]\n","        p3 = ax.contourf(plot_values, levels=100, cmap='jet')\n","        fig.colorbar(p3, ax=ax)\n","        ax.set_title(f'Error U_{j} of angle {angle}, RMSE: {actual_rmse[j]:.2f} m/s')\n","        ax.set_xlabel('X-axis')\n","        ax.set_ylabel('Z-axis')\n","\n","    plt.tight_layout()  # Adjust layout to prevent overlap\n","\n","    # Save the graph\n","    plt.savefig(model_dir + f'/Graph_test_angle_{angle}.png')"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}